---
layout: post
title:  "RMPE: Regional Multi-person Pose Estimation"
subtitle: "ICCV 2017"
date:   2019-07-05 
categories: [paper]
---

> 1. SPPE对目标在不在中心位置很敏感吗？有没有针对这方面的SPPE改进或研究？
> 2. 之前在姿态估计中没有人使用过STN吗？
> 3. 这篇论文在多个人很近的时候怎么办？不能处理多人重叠

[源代码](https://github.com/MVIG-SJTU/AlphaPose)

目前行人检测器在行人定位和识别上仍然存在小的错误，因此仅依赖行人检测结果的single-person pose estimator (SPPE) 会出现失误。

本文设计框架使其能够适应不准确的行人bbox和多余的检测，包含三个组件：

1. Symmetric Spatial Transformer Network (SSTN)
2. Parametric Pose Non Maximum-Suppression (NMS)
3. Pose-Guided Proposals Generator (PGPG)

> how?

# Introduction

多人姿态估计方法：

+ two-step framework ：自顶向下的方法，先检测行人，然后对每个行人检测关键点
  + 准确性高度依赖于bbox的质量
+ part-based framework ：自底向上的方法，先检测身体部件，再连接起来
  + 在多个行人过于接近时难以组合
  + 由于仅使用二阶身体部件依赖，无法从全局姿态视角识别身体部件

> second-order body parts dependence？为什么？

SPPE对bbox错误非常敏感。使用faster-RCNN和hourglass组合：

1. 定位错误：即使是IoU>0.5的bboxx，无法正确识别行人姿势

   ![RMPE1](https://github.com/suoluowan/learngit/blob/master/images/RMPE1.png?raw=true)

2. 多余检测：当一个目标有了多个bbox，一个目标会做多个姿态估计

   ![RMPE2](https://github.com/suoluowan/learngit/blob/master/images/RMPE2.png?raw=true)

> 图1中不应该毫无响应，像右边只是框进去的背景变大了，不应该连一个关节都检测不出来
>
> 多余检测应该可以在检测器后面加NMS或者其他去除的，应该算不上姿态估计的问题，而是行人检测的问题
>
> SPPE对定位错误很敏感，有什么依据吗？

SSTN：从不准确的bbox中提取高质量的单人区域

parametric pose NMS：针对多余检测；使用姿态距离度量比较姿态相似性来消除多余的姿态。

PGPG：增加训练样本；学习检测器输出的行人的姿态分布，模拟生成bbox。

> how? and why?

# Related Work

## Multi Person Pose Estimation

**Part-based Framework ：**

[9]：解决严重遮挡问题

[15]：k-poselets

DeepCut：使用积分线性编码聚合身体部件

> 这种方法检测的身体部件还是关节？

While part-based methods have demonstrated good performance, their body-part detectors can be vulnerable since only small local regions are considered. 

> ？？？

**Two-step Framework ：**

[34]：pictorial structure models for pose estimation. 

[21]：faster R-CNN + unary DeeperCut

Our paper aims to solve the problem of imperfect human detection in the two-step framework in order to maximize the power of SPPE. 

# RMPE

> pose proposals是什么？
>
> parallel SPPE：避免局部最小化并利用STTN的能力。how？不用并行就会出现局部最小并无法使用STTN吗？
>
> 增加训练样本的原因是什么？目前的数据集过小？增强数据多样性？

## Symmetric STN and Parallel SPPE 

> hourglass的论文证明了human proposal的小的平移和裁剪会极大影响SPPE性能？？？

Our symmetric STN + parallel SPPE was introduced to enhance SPPE when given imperfect human proposals.  

> 改进SPPE使其对bbox的错误不过于敏感？
>
> no，在SPPE前后加了STN和SDTN修正SPPE的输入，使其更加准确。

we use the STN to extract high quality dominant human proposals. 

> STN是已经提出来的方法，能自动选择感兴趣区域，本文只是复用？没有改进？
>
> yes

使用STN将bbox坐标做一个仿射变换，extract high quality dominant human proposal regions，输入到SPPE中，输出的结果再使用SDTN映射到运来的坐标上。

Parallel SPPE：只使用STN，不使用SDTN。目的是向STN反向传播center-located pose errors. 如果STN提取出的pose不是center-located，会反向传播更大的错误。不参与测试

To be more specific, the output of this SPPE branch is directly compared to labels of center located ground truth poses. 

> center located ground truth poses是怎么得到的？

It helps to avoid a poor solution (local minimum) where the STN does not transform the pose to the center of extracted human regions. The likelihood of reaching a local minimum is increased because compensation from the SDTN will make the network generate fewer errors. 

> ？？？

replace parallel SPPE with a center-located poses regression loss in the output of SPPE (before SDTN)会降低性能：

STN生成的pose不可能完美地匹配label，由于STN是和SPPE一起训练，这种错误会影响SPPE的参数学习，从而影响其性能。所以应该将STN的中心位置学习与SPPE分开。

> 为什么STN还要经过SPPE，是因为没有STN结果的标注吗？

## Parametric Pose NMS

不同于检测器对Bbox做NMS，这个是对关节做NMS

pose NMS：选择置信度最高的pose，消除距离近的pose。

> 这里的pose是指关节点已经联合起来的pose，还是每一个关节点每一个关节点地进行NMS？
>
> 应该是关节点连起来的pose
>
> 那能不能每一个关节点每一个关节点地做NMS？有没有意义？

Pose Distance：

![RMPE3](https://github.com/suoluowan/learngit/blob/master/images/RMPE3.png?raw=true)

计算两个pose的每一个关节点。如果pose j的一个关节点在i的对应关节点的box中，且它们的score都很高，输出会接近1。整体计算了两个pose之间匹配的关节点的数目。

![RMPE4](https://github.com/suoluowan/learngit/blob/master/images/RMPE4.png?raw=true)

![RMPE5](https://github.com/suoluowan/learngit/blob/master/images/RMPE5.png?raw=true)

> K是置信度，H是空间距离

our parameters can be determined in a data-driven manner ：Given the detected redundant poses, the four parameters in the eliminate criterion are optimized to achieve the maximal mAP for the validation set. 

> 除了pose参数是学出来的之外，这个pose NMS是本文设计的吗？
>
> yes

## PGPG

目的：make the SSTN+SPPE module adapt to the ’imperfect’ human proposals generated by the human detector.  增加不完美的human proposals使STTN和SPPE效果更好。

Insight: distribution of the relative offset between the detected bounding box and the ground truth bounding box varies across different poses.  

使用atomic pose（相当于将pose分类）计算其与GT的offset，每一类pose的offset满足一个高斯分布

训练的时候从该pose的分布中采样offset从而生成proposal

# Experiments

## dataset

MPII：

+ 3,844 training and 1,758 testing groups with both occluded and overlapped people. 
+ more than 28,000 training samples for single person pose estimation. 

use all the training data in the single person dataset and 90% of the multi-person training set to fine-tune the SPPE, leaving 10% for validation. 

MSCOCO：

+ 105,698 training and around 80,000 testing human instances. 
+ The training set contains over 1 million total labeled key-points. 
+ The testing set are divided into four roughly equally sized splits: test-challenge, test-dev, test-standard, and test-reserve. 

## Implementation

human detector: VGG-based SSD-512，检测到的proposal向外扩30%；ResNet152 based Faster-RCNN 

SPPE: stacked hourglass model；PyraNet  

STN: ResNet-18 

parallel SPPE: 4-stack hourglass network 

## Result

> 没有训练样本增强后性能下降极大，说明现有数据过少了？

直接将GT作为bbox检测本文框架的上界

> 这个上界应该等同于单人姿态估计

## Failure cases

1. 稀少的姿态
2. 多人重叠
3. miss detection
4. 与人相似的非人目标

> + 3和4应该是检测器的错误，two-stage的姿态估计无法修正miss detection，目前的two-stage使用的姿态估计器都假设检测器检测出来的都是人？有没有在姿态估计中判断是不是人的方法？
> + 多人重叠一个可能是检测器没有检测出多个人来，另一个可能是检测出来多个框，但是由于重叠，姿态估计对这两个框估计的姿态特别接近从而被pose NMS去掉了其中一个































